{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('JupyterProjects/EYE-SEA/DataSets/MARVEL_code')\n",
    "\n",
    "import import_ipynb\n",
    "#import Dataset_loader_MARVEL\n",
    "import ResNetCaps\n",
    "import Pets_Loader\n",
    "import Animals_Loader\n",
    "\n",
    "verbose = False\n",
    "USE_CUDA = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CIFAR10_USE = False\n",
    "MARVEL_USE = False\n",
    "PETS_USE = False\n",
    "Animals_USE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MARVEL_dataset(Dataset):\n",
    "    def __init__(self, dat_file,train = True, transform = None):   \n",
    "        self.root_dir = os.path.dirname(dat_file)\n",
    "        datContent = [i.strip().split(',') for i in open(dat_file).readlines()]\n",
    "        if train:\n",
    "            csv_file = os.path.join(self.root_dir, \"data_Train.csv\")\n",
    "        else:\n",
    "            csv_file = os.path.join(self.root_dir, \"data_Test.csv\")\n",
    "        with open(csv_file, \"w\") as f:\n",
    "            writer = csv.writer(f,delimiter=',')\n",
    "            writer.writerow([\"counter\", \"set\", \"class\", \"label\",\"location\"])\n",
    "            for line in datContent:\n",
    "                if train and line[1]=='1':\n",
    "                    if not(line[4] == '-'):\n",
    "                        writer.writerows([line])  \n",
    "                if not(train) and line[1] == '2':\n",
    "                    if not(line[4]=='-'):\n",
    "                        writer.writerows([line]) \n",
    "                \n",
    "        self.MARVEL_datafile = pd.read_csv(csv_file)       \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.MARVEL_datafile)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.MARVEL_datafile.iloc[idx,4]\n",
    "        image = self.__loadfile(img_name)\n",
    "        target = self.MARVEL_datafile.iloc[idx,2]\n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)\n",
    "            sample = self.transform(image)\n",
    "        else:\n",
    "            sample = image\n",
    "        return (sample,target)\n",
    "    \n",
    "    def __loadfile(self, data_file):\n",
    "        image = io.imread(data_file)\n",
    "        if len(image.shape)<3:\n",
    "            image = np.stack((image,)*3, axis=-1)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "if CIFAR10_USE: \n",
    "    NUM_CLASSES = 10\n",
    "    print(\"CIFAR10\")\n",
    "    image_datasets = {'train': datasets.CIFAR10('../data', train=True, download=True, transform=dataset_transform),'val': datasets.CIFAR10('../data', train=False, download=True, transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "if MARVEL_USE: \n",
    "    NUM_CLASSES = 26\n",
    "    print(\"MARVEL\")\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/marveldataset2016-master/FINAL.dat\"\n",
    "\n",
    "    image_datasets = {'train': MARVEL_dataset(dat_file,train = True,transform=dataset_transform),'val': MARVEL_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "    \n",
    "if  PETS_USE:\n",
    "    NUM_CLASSES = 37\n",
    "    print(\"PETS\")\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Pets/Pet_Datasets\"\n",
    "\n",
    "    image_datasets = {'train': Pets_Loader.PETS_dataset(dat_file,train = True,transform=dataset_transform),'val': Pets_Loader.PETS_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")    \n",
    "    \n",
    "if  Animals_USE:\n",
    "    NUM_CLASSES = 50\n",
    "    print(\"Animals\")\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Animals_with_Attributes2/JPEGImages\"\n",
    "\n",
    "    image_datasets = {'train': Animals_Loader.Animals_dataset(dat_file,train = True,transform=dataset_transform),'val': Animals_Loader.Animals_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")    \n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_left_once(A):\n",
    "    a =  []\n",
    "    AD = A.detach().cpu().numpy()\n",
    "    temp = AD[0,:]\n",
    "\n",
    "    for index in range(1,len(AD)):\n",
    "        a = np.concatenate([a,AD[index]])\n",
    "    a = np.concatenate([a,temp])\n",
    "    a_tensor = torch.from_numpy(a)\n",
    "    return ((a_tensor.view(len(a),1)).float()).to(device)\n",
    "\n",
    "def shift_left(lst, n):\n",
    "    assert (n >= 0), \"n should be non-negative integer\"\n",
    "    for _ in range(n):\n",
    "        shift_left_once(lst)\n",
    "\n",
    "def circulant(A):\n",
    "    r = A.size()[0]\n",
    "    circ_list_a = []\n",
    "    circ_list_a.append(A)\n",
    "    \n",
    "    a = shift_left_once(A)\n",
    "    for i in range(r-1):   \n",
    "        circ_list_a.append(a)      \n",
    "        a = shift_left_once(a)\n",
    "\n",
    "    \n",
    "    circ = torch.cat(circ_list_a,0).detach().requires_grad_()\n",
    "    circ = circ.view([r,r])\n",
    "    if verbose: print(\"circular matrix {}\".format(circ))\n",
    "    return circ.to(device)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction(nn.Module):\n",
    "    def __init__(self,NUM_CLASSES):\n",
    "        super(Interaction, self).__init__()\n",
    "        self.modelCaps1 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "        self.modelCaps2 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "        \n",
    "        self.W1 = torch.randn(NUM_CLASSES,NUM_CLASSES)\n",
    "        self.W1.requires_grad = True\n",
    "        \n",
    "        self.W2 = torch.randn(NUM_CLASSES,NUM_CLASSES)\n",
    "        self.W2.requires_grad = True\n",
    "        \n",
    "        self.modelLin = nn.Linear(NUM_CLASSES, NUM_CLASSES)\n",
    "        self.NClass = NUM_CLASSES\n",
    "\n",
    "    def cuda(self, device=None):\n",
    "        self = super().cuda(device)\n",
    "        self.W1 = self.W1.cuda(device)\n",
    "        self.W2 = self.W2.cuda(device)\n",
    "        return self \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        digit1,_ = self.modelCaps1(inputs)\n",
    "        digit2,_ = self.modelCaps2(inputs)\n",
    "        \n",
    "        output = self.modelLin(self.interaction(digit1,digit2))\n",
    "        return output\n",
    "\n",
    "    def model_loss(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        v_c = x\n",
    "        if verbose: print(\"v_c {}\".format(v_c.size()))\n",
    "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
    "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
    "\n",
    "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "\n",
    "        loss = loss.sum(dim=1).mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def interaction(self,x,y):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "         \n",
    "        Z_list = []\n",
    "        labels_size = x.size()[1]\n",
    "        batch = min(x.size()[0],batch_size)\n",
    "        for i in range(batch):\n",
    "        \n",
    "            xi = torch.sum(x[i,:,:,0],dim=1)\n",
    "            yi = torch.sum(y[i,:,:,0],dim=1)\n",
    "            \n",
    "            xi = xi.view(self.NClass,1)\n",
    "            yi = yi.view(self.NClass,1)\n",
    "\n",
    "            V = torch.mm(self.W1,xi)   #< questo fa batch-matrix con matrix ?\n",
    "            C = torch.mm(self.W2,yi)\n",
    "\n",
    "            #CIRCOLANTE\n",
    "            A = circulant(V)\n",
    "            B = circulant(C)\n",
    "\n",
    "            #INTERACTION MOMENT\n",
    "            F = torch.mm(B,V)\n",
    "            G = torch.mm(A,C)\n",
    "            \n",
    "            M = torch.add(F,G)\n",
    "\n",
    "            Z_list.append(M)\n",
    "            \n",
    "        Z = torch.cat(Z_list,0)\n",
    "        if verbose : print(Z.size())\n",
    "        Z = Z.view(batch,labels_size)\n",
    "        \n",
    "        return Z   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decrease(optimizer, lr_clip):  \n",
    "    for param_group in optimizer.param_groups:\n",
    "        init_lr = param_group['lr'] \n",
    "        param_group['lr'] = init_lr*lr_clip\n",
    "        \n",
    "def isnan(x):\n",
    "    return x != x        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "threshold = 30\n",
    "lr_clip = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Interaction(NUM_CLASSES)\n",
    "#model = model.to(device)\n",
    "model = model.cuda(device)#<for weights matrix\n",
    "\n",
    "#optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = lr)\n",
    "n_epochs = 100\n",
    "#train\n",
    "start = time.time()\n",
    "#batch_id = 100\n",
    "#inputs, labels = next(iter(dataloaders['train']))\n",
    "accuracy_train = []\n",
    "loss_train = []\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    model.train() \n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    print('epoch {}:{}'.format(epoch+1, n_epochs)) \n",
    "    for batch_id, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "        if MARVEL_USE: labels = labels-1\n",
    "        labels =torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _,label = torch.max(labels, 1)\n",
    "\n",
    "        loss = criterion(outputs, label.long())\n",
    "        if isnan(loss): \n",
    "            request_exit = True\n",
    "            print(\"lost loss\")\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        train_accuracy += (sum(np.argmax(outputs.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            print(\"train accuracy:\", sum(np.argmax(outputs.data.cpu().numpy(), 1) == \n",
    "                                   np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "            print(\"loss : {}\".format(loss.data[0]))\n",
    "            if verbose: print(\"masked {}\".format(np.argmax(masked.data.cpu().numpy(), 1)))\n",
    "            if verbose: print(\"labels {}\".format(np.argmax(labels.data.cpu().numpy(), 1)))\n",
    "        #                batch_accuracy.append(sum(np.argmax(preds.data.cpu().numpy(), 1) == \n",
    "        #                                       np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "    accuracy_train.append(train_accuracy/batch_id)#len(dataloaders['train']))\n",
    "    loss_train.append(train_loss/batch_id)#len(dataloaders['train']))\n",
    "    \n",
    "    if epoch>2:\n",
    "        if accuracy_train[-1]<(accuracy_train[-2]*0.5):\n",
    "            print(\"Learnining rate decrease\")\n",
    "            lr_decrease(optimizer,lr_clip)\n",
    "   # if epoch == threshold:\n",
    "    #    print(\"Learnining rate decrease\")\n",
    "     #   lr_decrease(optimizer, lr_clip)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Training time execution {}\".format(end-start))\n",
    "print(\"Loss value for training phase: {}\".format(train_loss / batch_id))#len(dataloaders['train'])))\n",
    "print(\"Accuracy value for training phase: {}\".format(train_accuracy / batch_id))#len(dataloaders['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training time execution {}\".format(end-start))\n",
    "print(\"Loss value for training phase: {}\".format(train_loss / batch_id))#len(dataloaders['train'])))\n",
    "print(\"Accuracy value for training phase: {}\".format(train_accuracy / batch_id))#len(dataloaders['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train[-1]=train_accuracy/batch_id#len(dataloaders['train']))\n",
    "loss_train[-1]=(train_loss/batch_id)#len(dataloaders['train']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_train, color='g')\n",
    "plt.plot(epochs, accuracy_train, color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy - Loss')\n",
    "plt.title('Training phase')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0 \n",
    "start = time.time()\n",
    "for batch_id, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "    if MARVEL_USE: labels = labels-1\n",
    "\n",
    "    labels = torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "    if USE_CUDA: inputs, labels = inputs.to(device), labels.to(device)#cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _,label = torch.max(labels, 1)\n",
    "    loss = criterion(outputs, label.long())\n",
    "\n",
    "    test_loss += loss.data[0]\n",
    "    test_accuracy += (sum(np.argmax(outputs.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "\n",
    "    if batch_id % 100 == 0:\n",
    "        print(\"test accuracy:\", sum(np.argmax(outputs.data.cpu().numpy(), 1) == \n",
    "                               np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "end = time.time()\n",
    "print(\"Test time execution {}\".format(end-start))\n",
    "print(\"Loss value for test phase: {}\".format(test_loss /  len(dataloaders['val']))) \n",
    "print(\"Accuracy value for test phase: {}\".format(test_accuracy / len(dataloaders['val'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
