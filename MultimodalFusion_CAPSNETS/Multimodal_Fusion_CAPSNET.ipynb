{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ResNetCaps.ipynb\n",
      "importing Jupyter notebook from Pets_Loader.ipynb\n",
      "importing Jupyter notebook from Animals_Loader.ipynb\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('JupyterProjects/EYE-SEA/DataSets/MARVEL_code')\n",
    "\n",
    "import import_ipynb\n",
    "#import Dataset_loader_MARVEL\n",
    "import ResNetCaps\n",
    "import Pets_Loader\n",
    "import Animals_Loader\n",
    "\n",
    "verbose = False\n",
    "USE_CUDA = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CIFAR10_USE = True\n",
    "MARVEL_USE = False\n",
    "PETS_USE = False\n",
    "Animals_USE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MARVEL_dataset(Dataset):\n",
    "    def __init__(self, dat_file,train = True, transform = None):   \n",
    "        self.root_dir = os.path.dirname(dat_file)\n",
    "        datContent = [i.strip().split(',') for i in open(dat_file).readlines()]\n",
    "        if train:\n",
    "            csv_file = os.path.join(self.root_dir, \"data_Train.csv\")\n",
    "        else:\n",
    "            csv_file = os.path.join(self.root_dir, \"data_Test.csv\")\n",
    "        with open(csv_file, \"w\") as f:\n",
    "            writer = csv.writer(f,delimiter=',')\n",
    "            writer.writerow([\"counter\", \"set\", \"class\", \"label\",\"location\"])\n",
    "            for line in datContent:\n",
    "                if train and line[1]=='1':\n",
    "                    if not(line[4] == '-'):\n",
    "                        writer.writerows([line])  \n",
    "                if not(train) and line[1] == '2':\n",
    "                    if not(line[4]=='-'):\n",
    "                        writer.writerows([line]) \n",
    "                \n",
    "        self.MARVEL_datafile = pd.read_csv(csv_file)       \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.MARVEL_datafile)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.MARVEL_datafile.iloc[idx,4]\n",
    "        image = self.__loadfile(img_name)\n",
    "        target = self.MARVEL_datafile.iloc[idx,2]\n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)\n",
    "            sample = self.transform(image)\n",
    "        else:\n",
    "            sample = image\n",
    "        return (sample,target)\n",
    "    \n",
    "    def __loadfile(self, data_file):\n",
    "        image = io.imread(data_file)\n",
    "        if len(image.shape)<3:\n",
    "            image = np.stack((image,)*3, axis=-1)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Initializing Datasets and Dataloaders...\n",
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "if CIFAR10_USE: \n",
    "    NUM_CLASSES = 10\n",
    "    print(\"CIFAR10\")\n",
    "    image_datasets = {'train': datasets.CIFAR10('../data', train=True, download=True, transform=dataset_transform),'val': datasets.CIFAR10('../data', train=False, download=True, transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "if MARVEL_USE: \n",
    "    NUM_CLASSES = 26\n",
    "    print(\"MARVEL\")\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/marveldataset2016-master/FINAL.dat\"\n",
    "\n",
    "    image_datasets = {'train': MARVEL_dataset(dat_file,train = True,transform=dataset_transform),'val': MARVEL_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "    \n",
    "if  PETS_USE:\n",
    "    NUM_CLASSES = 37\n",
    "    print(\"PETS\")\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Pets/Pet_Datasets\"\n",
    "\n",
    "    image_datasets = {'train': Pets_Loader.PETS_dataset(dat_file,train = True,transform=dataset_transform),'val': Pets_Loader.PETS_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")    \n",
    "    \n",
    "if  Animals_USE:\n",
    "    NUM_CLASSES = 50\n",
    "    print(\"Animals\")\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Animals_with_Attributes2/JPEGImages\"\n",
    "\n",
    "    image_datasets = {'train': Animals_Loader.Animals_dataset(dat_file,train = True,transform=dataset_transform),'val': Animals_Loader.Animals_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")    \n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_left_once(A):\n",
    "    a =  []\n",
    "    AD = A.detach().cpu().numpy()\n",
    "    temp = AD[0,:]\n",
    "\n",
    "    for index in range(1,len(AD)):\n",
    "        a = np.concatenate([a,AD[index]])\n",
    "    a = np.concatenate([a,temp])\n",
    "    a_tensor = torch.from_numpy(a)\n",
    "    return ((a_tensor.view(len(a),1)).float()).to(device)\n",
    "\n",
    "def shift_left(lst, n):\n",
    "    assert (n >= 0), \"n should be non-negative integer\"\n",
    "    for _ in range(n):\n",
    "        shift_left_once(lst)\n",
    "\n",
    "def circulant(A):\n",
    "    r = A.size()[0]\n",
    "    circ_list_a = []\n",
    "    circ_list_a.append(A)\n",
    "    \n",
    "    a = shift_left_once(A)\n",
    "    for i in range(r-1):   \n",
    "        circ_list_a.append(a)      \n",
    "        a = shift_left_once(a)\n",
    "\n",
    "    \n",
    "    circ = torch.cat(circ_list_a,0).detach().requires_grad_()\n",
    "    circ = circ.view([r,r])\n",
    "    if verbose: print(\"circular matrix {}\".format(circ))\n",
    "    return circ.to(device)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction(nn.Module):\n",
    "    def __init__(self,NUM_CLASSES):\n",
    "        super(Interaction, self).__init__()\n",
    "        self.modelCaps1 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "        self.modelCaps2 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "        \n",
    "        self.W1 = torch.randn(NUM_CLASSES,NUM_CLASSES)\n",
    "        self.W1.requires_grad = True\n",
    "        \n",
    "        self.W2 = torch.randn(NUM_CLASSES,NUM_CLASSES)\n",
    "        self.W2.requires_grad = True\n",
    "        \n",
    "        self.modelLin = nn.Linear(NUM_CLASSES, NUM_CLASSES)\n",
    "        self.NClass = NUM_CLASSES\n",
    "\n",
    "    def cuda(self, device=None):\n",
    "        self = super().cuda(device)\n",
    "        self.W1 = self.W1.cuda(device)\n",
    "        self.W2 = self.W2.cuda(device)\n",
    "        return self \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        digit1,_ = self.modelCaps1(inputs)\n",
    "        digit2,_ = self.modelCaps2(inputs)\n",
    "        \n",
    "        output = self.modelLin(self.interaction(digit1,digit2))\n",
    "        return output\n",
    "        \n",
    "    def interaction(self,x,y):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "         \n",
    "        Z_list = []\n",
    "        labels_size = x.size()[1]\n",
    "        batch = min(x.size()[0],batch_size)\n",
    "        for i in range(batch):\n",
    "        \n",
    "            xi = torch.sum(x[i,:,:,0],dim=1)\n",
    "            yi = torch.sum(y[i,:,:,0],dim=1)\n",
    "            \n",
    "            xi = xi.view(self.NClass,1)\n",
    "            yi = yi.view(self.NClass,1)\n",
    "\n",
    "            V = torch.mm(self.W1,xi)   #< questo fa batch-matrix con matrix ?\n",
    "            C = torch.mm(self.W2,yi)\n",
    "\n",
    "            #CIRCOLANTE\n",
    "            A = circulant(V)\n",
    "            B = circulant(C)\n",
    "\n",
    "            #INTERACTION MOMENT\n",
    "            F = torch.mm(B,V)\n",
    "            G = torch.mm(A,C)\n",
    "            \n",
    "            M = torch.add(F,G)\n",
    "\n",
    "            Z_list.append(M)\n",
    "            \n",
    "        Z = torch.cat(Z_list,0)\n",
    "        if verbose : print(Z.size())\n",
    "        Z = Z.view(batch,labels_size)\n",
    "        \n",
    "        return Z   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decrease(optimizer, lr_clip):  \n",
    "    for param_group in optimizer.param_groups:\n",
    "        init_lr = param_group['lr'] \n",
    "        param_group['lr'] = init_lr*lr_clip\n",
    "        \n",
    "def isnan(x):\n",
    "    return x != x        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "threshold = 30\n",
    "lr_clip = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNetCaps.ipynb:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"from torch.autograd import Variable\\n\",\n",
      "ResNetCaps.ipynb:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"USE_CUDA = True\\n\",\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.03125\n",
      "loss : {} 2.2873988151550293\n",
      "train accuracy: 0.09375\n",
      "loss : {} 2.3072400093078613\n",
      "train accuracy: 0.15625\n",
      "loss : {} 2.0171470642089844\n",
      "train accuracy: 0.3125\n",
      "loss : {} 1.7666115760803223\n",
      "train accuracy: 0.4375\n",
      "loss : {} 1.462256908416748\n",
      "train accuracy: 0.46875\n",
      "loss : {} 1.441605567932129\n",
      "train accuracy: 0.71875\n",
      "loss : {} 1.0229971408843994\n",
      "train accuracy: 0.46875\n",
      "loss : {} 1.624979019165039\n",
      "train accuracy: 0.46875\n",
      "loss : {} 1.2594122886657715\n",
      "train accuracy: 0.46875\n",
      "loss : {} 1.4174882173538208\n",
      "train accuracy: 0.65625\n",
      "loss : {} 0.8656806349754333\n",
      "train accuracy: 0.53125\n",
      "loss : {} 1.1029000282287598\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.8873865604400635\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.7125087380409241\n",
      "train accuracy: 0.65625\n",
      "loss : {} 1.1779483556747437\n",
      "train accuracy: 0.625\n",
      "loss : {} 1.1438820362091064\n",
      "epoch 2:10\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.8594723343849182\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.602633535861969\n",
      "train accuracy: 0.6875\n",
      "loss : {} 0.9364101886749268\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.6220800876617432\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.45883476734161377\n",
      "train accuracy: 0.65625\n",
      "loss : {} 0.8130853772163391\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.8536162972450256\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.7906876802444458\n",
      "train accuracy: 0.65625\n",
      "loss : {} 0.8777275085449219\n",
      "train accuracy: 0.65625\n",
      "loss : {} 1.0964531898498535\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.760370671749115\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.6906648874282837\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.46405094861984253\n",
      "train accuracy: 0.8125\n",
      "loss : {} 0.6840572357177734\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.9289101362228394\n",
      "train accuracy: 0.8125\n",
      "loss : {} 0.6767274141311646\n",
      "epoch 3:10\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.5811715126037598\n",
      "train accuracy: 0.625\n",
      "loss : {} 1.0182665586471558\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.7072691321372986\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.5430516004562378\n",
      "train accuracy: 0.6875\n",
      "loss : {} 0.8028106093406677\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.6585482358932495\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.43655043840408325\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.7256947755813599\n",
      "train accuracy: 0.8125\n",
      "loss : {} 0.571510374546051\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.5716739892959595\n",
      "train accuracy: 0.65625\n",
      "loss : {} 0.8807805180549622\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.5739269852638245\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.8746406435966492\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.5069085359573364\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.7503405809402466\n",
      "train accuracy: 0.8125\n",
      "loss : {} 0.6009858846664429\n",
      "epoch 4:10\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.558175802230835\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.43079161643981934\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.7297623157501221\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.5327408909797668\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.3337228298187256\n",
      "train accuracy: 0.65625\n",
      "loss : {} 1.2818987369537354\n",
      "train accuracy: 0.6875\n",
      "loss : {} 0.7632845640182495\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.8332489728927612\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.4041977524757385\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.23750919103622437\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.7777570486068726\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.4962710738182068\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.4725798964500427\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.2020464837551117\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.7700843214988708\n",
      "train accuracy: 0.59375\n",
      "loss : {} 0.9513303637504578\n",
      "epoch 5:10\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.5524737238883972\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.36084142327308655\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.3759685158729553\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.36594676971435547\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.5069581270217896\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.334514319896698\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.1317576766014099\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.6032288074493408\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.25625079870224\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.49429428577423096\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.25258299708366394\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.27151674032211304\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.6241849064826965\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.33092570304870605\n",
      "train accuracy: 0.71875\n",
      "loss : {} 0.5753760933876038\n",
      "train accuracy: 0.75\n",
      "loss : {} 0.5704245567321777\n",
      "epoch 6:10\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.637299120426178\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.36794593930244446\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.45083293318748474\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.3830512762069702\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.3287654519081116\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.2636262774467468\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.2989192008972168\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.34031158685684204\n",
      "train accuracy: 1.0\n",
      "loss : {} 0.09150142222642899\n",
      "train accuracy: 0.78125\n",
      "loss : {} 0.5541857481002808\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.1928355097770691\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.4189166724681854\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.2768775224685669\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.17959082126617432\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.357728511095047\n",
      "train accuracy: 0.8125\n",
      "loss : {} 0.5107260942459106\n",
      "epoch 7:10\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.2456183284521103\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.43886059522628784\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.19469362497329712\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.2744073271751404\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.25881263613700867\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.32764628529548645\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.2568865418434143\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.2670447826385498\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.19300693273544312\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.19714535772800446\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.40744638442993164\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.15578289330005646\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.1633782535791397\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.26037099957466125\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.2375463992357254\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.33887404203414917\n",
      "epoch 8:10\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.22138074040412903\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.19721174240112305\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.22195887565612793\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.18530452251434326\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.17606160044670105\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.11250802874565125\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.30936723947525024\n",
      "train accuracy: 1.0\n",
      "loss : {} 0.07607299089431763\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.1834360957145691\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.13378998637199402\n",
      "train accuracy: 0.875\n",
      "loss : {} 0.21251091361045837\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.20226310193538666\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.18547679483890533\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.3722638189792633\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.2078145146369934\n",
      "train accuracy: 0.84375\n",
      "loss : {} 0.265413373708725\n",
      "epoch 9:10\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.10319806635379791\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.1613839715719223\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.08284485340118408\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.131996750831604\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.14149236679077148\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.13433358073234558\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.09709686040878296\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.09370581060647964\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.229559063911438\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.3081657290458679\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.09629479795694351\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.17751245200634003\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.3043084740638733\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.16933614015579224\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.057507485151290894\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.07452946901321411\n",
      "epoch 10:10\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.25232723355293274\n",
      "train accuracy: 1.0\n",
      "loss : {} 0.08023589849472046\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.22668766975402832\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.09324757754802704\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.11537540704011917\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.21335305273532867\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.23848368227481842\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.14400839805603027\n",
      "train accuracy: 1.0\n",
      "loss : {} 0.08130569756031036\n",
      "train accuracy: 0.96875\n",
      "loss : {} 0.12631748616695404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.875\n",
      "loss : {} 0.4315178096294403\n",
      "train accuracy: 1.0\n",
      "loss : {} 0.026598259806632996\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.3104443848133087\n",
      "train accuracy: 0.90625\n",
      "loss : {} 0.23305141925811768\n",
      "train accuracy: 0.9375\n",
      "loss : {} 0.1816454529762268\n",
      "train accuracy: 1.0\n",
      "loss : {} 0.04419343173503876\n",
      "Training time execution 5643.683134555817\n",
      "Loss value for training phase: 0.13625019788742065\n",
      "Accuracy value for training phase: 0.9527351247600768\n"
     ]
    }
   ],
   "source": [
    "model = Interaction(NUM_CLASSES)\n",
    "#model = model.to(device)\n",
    "model = model.cuda(device)\n",
    "\n",
    "#optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = lr)\n",
    "n_epochs = 10\n",
    "#train\n",
    "start = time.time()\n",
    "#batch_id = 100\n",
    "#inputs, labels = next(iter(dataloaders['train']))\n",
    "accuracy_train = []\n",
    "loss_train = []\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    model.train() \n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    print('epoch {}:{}'.format(epoch+1, n_epochs)) \n",
    "    for batch_id, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "        if MARVEL_USE: labels = labels-1\n",
    "        labels =torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _,label = torch.max(labels, 1)\n",
    "\n",
    "        loss = criterion(outputs, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        train_accuracy += (sum(np.argmax(outputs.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            print(\"train accuracy:\", sum(np.argmax(outputs.data.cpu().numpy(), 1) == \n",
    "                                   np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "            print(\"loss : {}\",format(loss.data[0]))\n",
    "            if verbose: print(\"masked {}\".format(np.argmax(masked.data.cpu().numpy(), 1)))\n",
    "            if verbose: print(\"labels {}\".format(np.argmax(labels.data.cpu().numpy(), 1)))\n",
    "        #                batch_accuracy.append(sum(np.argmax(preds.data.cpu().numpy(), 1) == \n",
    "        #                                       np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "    accuracy_train.append(train_accuracy/len(dataloaders['train']))\n",
    "    loss_train.append(train_loss/len(dataloaders['train']))\n",
    "    \n",
    "    if epoch>2:\n",
    "        if accuracy_train[-1]<(accuracy_train[-2]*0.5):\n",
    "            print(\"Learnining rate decrease\")\n",
    "            lr_decrease(optimizer,lr_clip)\n",
    "    if epoch == threshold:\n",
    "        print(\"Learnining rate decrease\")\n",
    "        lr_decrease(optimizer, lr_clip)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Training time execution {}\".format(end-start))\n",
    "print(\"Loss value for training phase: {}\".format(train_loss / len(dataloaders['train'])))\n",
    "print(\"Accuracy value for training phase: {}\".format(train_accuracy / len(dataloaders['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VPX1+PH3SQIJkLDv+47sJCICKigoIqioUBArLiT4s9qqta7ftn6/j9qqVVuXVlsICK6AuNSKigooWFEJCTvKEnYChDWEkJDl/P64l2ESgUxgJneSnNfzzJOZO3fuPTM83HM/u6gqxhhjDECE1wEYY4wJH5YUjDHG+FhSMMYY42NJwRhjjI8lBWOMMT6WFIwxxvhYUjBVhohEiki2iLQO5r7BJiI7ROTS8j6vMQBRXgdgzOmISLbfy5pAHlDovv5/qvpWWY6nqoVAbLD3NaYysaRgwpaq+i7KIrIFSFLVL0+3v4hEqWpBecRmTGVl1UemwhKRJ0Vkloi8IyJHgJtFZICIfCcih0QkQ0ReEpFq7v5RIqIi0tZ9/ab7/qcickRElohIu7Lu675/lYisF5HDIvKyiPxXRG4rJe533WOliEjPErsliMgq93jviEi0+9kGIvKJiGSKyEER+Y+ItPA7dqKIbHGPmy4iN/q9lyQiP7qf+1REWp3zP4KpdCwpmIrueuBtoA4wCygA7gUaAhcBw4H/d4bP3wT8EagPbAOeKOu+ItIYmA086J53M9CvlLhvcOOuD8wBPhAR/5L7WOAKoD1wPjDB3R4BTAFaA22AfOBFN47awF+BK1Q1zv3+K933RrvxjQIaAd+75zemGEsKpqL7RlX/o6pFqnpMVZeq6veqWqCq6cBkYPAZPj9HVVNUNR94C+hzFvteDSxX1X+77/0N2FdK3N+r6gfu/s8CtYEL/N5/QVV3q+p+4OMT51LVTPdzx1Q1C/hzie+nQA8RiVHVDFVd626/E/izqv7kVrE9CfTzL2UYA5YUTMW33f+FiJwnInNFZLeIZAGP49y9n85uv+c5nLlx+XT7NvePQ51ZJncEGrfbqL3TPc4ZzyUisSKSLCLb3O+3APf7uUliPHA3sFtEPhaRzu4x2gD/cKvVDuEkrSKgZSlxmirGkoKp6EpO8/svYDXQUVVrA48BEuIYMvC7uIqIAKXdgfvq80Ukwt1/VwDnehBoB/Rzv98Q/zdV9VNVvRxoBmzE+T3ASUKJqlrX71FDVb8P4JymCrGkYCqbOOAwcFREunLm9oRg+RinYfgat13gXpx6+zPpJyKj3EbwB4AjwNIAzhWHU3I4KCINcJIeACLSzI2hJnAcOIpTGgD4J/B79zdBROqKyJjAv6KpKiwpmMrmd8CtOBfZf+E0PoeUqu4BxuE08u4HOgBpOOMqTucD4GbggPvZGwLsTvtXnEb1/cC3wKd+70XilCQy3PcH4lQloarvup991612WglcGdg3NFWJ2CI7xgSXiETiVAWNUdXFp3j/SaClqt5W3rEZUxorKRgTBCIy3K2SicbptpoP/OBxWMaUmSUFY4LjYiAdyMSplrleVc9UfWRMWLLqI2OMMT5WUjDGGONT4SbEa9iwobZt29brMIwxpkJZtmzZPlUtrat0xUsKbdu2JSUlxeswjDGmQhGRrYHsZ9VHxhhjfCwpGGOM8bGkYIwxxseSgjHGGB9LCsYYY3wsKRhjjPGxpGCMMcYnZElBRKaJyF4RWV3KfheISEGo53b/cd+P/Paz33K88HgoT2OMMRVaKEsK03EWTT8td4rhZ4DPQxgHAOkH03nh+xf4eP3HoT6VMcZUWCFLCqq6CGcBkTP5DfAesDdUcZxwZYcraRHXguTU5FCfyhhjKizP2hREpAVwPfBqAPveISIpIpKSmZl5VueLjIjk9j63M2/TPLYf3l76B4wxpgrysqH5BeBhVS0qbUdVnayqfVW1b6NGpc7ndFoT4ydSpEVMXz79rI9hjDGVmZdJoS8wU0S2AGOAV0TkulCesF29dgxtN5SpaVMpKj0XGWNMleNZUlDVdqraVlXbAnOAu1T1w1CfNykhia2HtzI/fX6oT2WMMRVOKLukvgMsAbqIyA4RSRSRO0XkzlCdMxDXnXcd9WvUZ2raVC/DMMaYsBSy9RRUdXwZ9r0tVHGUFBMVw4ReE3g15VX25eyjYc2G5XVqY4wJe1VyRHNifCLHC4/z5so3vQ7FGGPCSpVMCj2b9KRfi35MTZuKqnodjjHGhI0qmRQAkuKTWL13NT/s/MHrUIwxJmxU2aRwY48bqVWtlo1wNsYYP1U2KcRFxzG2+1hmrplJ9vFsr8MxxpiwUGWTAjhjFrKPZzN7zWyvQzHGmLBQpZPCgJYD6Nqwq1UhGWOMq0onBREhMT6RJTuWsDZzrdfhGGOM56p0UgCY0HsC1SKqMTXVRjgbY0yVTwqNazVm1HmjeH3l6+QV5HkdjjHGeKrKJwVwxizsy9nHRz995HUoxhjjKUsKwOXtL6dV7VYkp1mDszGmarOkgLMq28T4iXyx6Qu2HtrqdTjGGOMZSwqu2/vcDsBry1/zOBJjjPGOJQVXm7ptGNZhGNPSplFYVOh1OMYY4wlLCn4S4xPZnrWdL9O/9DoUY4zxhCUFP9d2uZaGNRtag7MxpsqypOAnOiqaW3rdwr9//Dd7j+71OhxjjCl3lhRKSExIJL8onzdWvOF1KMYYU+4sKZTQrVE3BrQcYKuyGWOqJEsKp5CUkMS6fetYsmOJ16EYY0y5sqRwCmO7jyW2eqxNqW2MqXJClhREZJqI7BWR1ad5/5cislJEVonItyLSO1SxlFVs9Vhu7H4js9bMIisvy+twjDGm3ISypDAdGH6G9zcDg1W1J/AEMDmEsZRZUkISOfk5zFo9y+tQjDGm3IQsKajqIuDAGd7/VlUPui+/A1qGKpaz0a9FP3o07mFjFowxVUq4tCkkAp+e7k0RuUNEUkQkJTMzs1wCEhGS4pP4YecPrNqzqlzOaYwxXvM8KYjIZThJ4eHT7aOqk1W1r6r2bdSoUbnFdnOvm6keWZ2pabYqmzGmavA0KYhILyAZGKWq+72M5VQa1GzA9eddzxsr3yC3INfrcIwxJuQ8Swoi0hp4H5igquu9iqM0SQlJHDh2gA9//NDrUIwxJuRC2SX1HWAJ0EVEdohIoojcKSJ3urs8BjQAXhGR5SKSEqpYzsWQdkNoW7etVSEZY6qEqFAdWFXHl/J+EpAUqvMHS4REMLHPRB776jE2H9xMu3rtvA7JGGNCxvOG5orgtj63ESERTEub5nUoxhgTUpYUAtCqTiuGdxzOa8tfs1XZjDGVmiWFACXGJ7LzyE7mbZrndSjGGBMylhQCdHXnq2lcq7FNkmeMqdQsKQSoemR1bu19K/9Z/x/2ZO/xOhxjjAkJSwplMDF+IgVFBby+4nWvQzHGmJCwpFAG5zU8j4tbX0xyWrKtymaMqZQsKZRRUnwS6/ev55tt33gdijHGBJ0lhTIa020MtaNr25TaxphKyZJCGdWqXovxPcbz7pp3OZx72OtwjDEmqCwpnIWkhCSOFRzjndXveB2KMcYElSWFs3B+s/Pp3aS3jVkwxlQ6lhTOgoiQlJDEsoxlLN+93OtwjDEmaCwpnKVf9vwl0ZHRTE21KbWNMZWHJYWzVK9GPUZ3G82bq97kWP4xr8MxxpigsKRwDpLikziUe4j3173vdSjGGBMUlhTOweC2g2lfr72tymaMqTTKlBREJEJEaocqmIomQiJIjE9k4ZaFbDyw0etwjDHmnJWaFETkbRGpLSK1gNXAWhF5MPShVQy2KpsxpjIJpKTQTVWzgOuAT4F2wISQRlWBNI9rzshOI5m+fDoFRQVeh2OMMeckkKRQTUSq4SSFj1Q1H7ApQv0kxieSkZ3Bpxs+9ToUY4w5J4EkhX8BW4BawCIRaQNkhTKoimZEpxE0jW1qk+QZYyq8UpOCqr6kqi1UdYQ6tgKXlfY5EZkmIntFZPVp3hcReUlENorIShFJOIv4w0K1yGrc1vs25q6fS8aRDK/DMcaYsxZIQ/O9bkOziMhUEUkFhgRw7OnA8DO8fxXQyX3cAbwawDHD1sT4iRRqITNWzPA6FGOMOWuBVB9NdBuahwH1cBqZny7tQ6q6CDhwhl1GAa+7pY/vgLoi0iyAeMJSpwadGNxmMMmptiqbMabiCiQpiPt3BPCGqq7x23YuWgDb/V7vcLf9PACRO0QkRURSMjMzg3Dq0EhKSGLTwU18vfVrr0MxxpizEkhSWCYin+MkhXkiEgcUhTas4lR1sqr2VdW+jRo1Ks9Tl8norqOpE13HRjgbYyqsQJJCIvAIcIGq5gDVgduDcO6dQCu/1y3dbRVWjWo1+GXPXzJn7RwOHjvodTjGGFNmgfQ+KsK5YP9BRJ4DBqrqyiCc+yPgFrcBuz9wWFUrfNedpIQkcgtyeXvV216HYowxZRZI76OngXuBte7jHhH5cwCfewdYAnQRkR0ikigid4rIne4unwDpwEZgCnDXWX6HsBLfLJ6EZgk2ZsEYUyFFBbDPCKCPW2JARGYAacD/nOlDqjq+lPcVuDvAOCuUpPgk7vrkLlIzUkloVmGHXxhjqqBAZ0mt6/e8TigCqUzG9xxPTFSMreFsjDl7qpB/BI5ug4MrYM9CyFof8tMGUlJ4CkgTkYU4XVEH4TQ8m9OoG1OXX3T7BW+teovnhj1HzWo1vQ7JGOOVwlw4fhDyDjh/jx+E4wdK/PV7P9/vuZaYZLPrQxD/TEjDLTUpqOo7IvIVcIG76WFscZ5SJSUk8cbKN3hv7XtM6G2TyhpToRUV+F3QT3MxP36ai35h7hkOLFC9LlSv5z7qQ63WJ59XrwfR9U++H9sh5F81kJICbq+gj068FpFtQOtQBVUZXNL6EjrV70RyWrIlBWPCTVEB5O2DvEzI3Qu5mZC313nu2+b3PP/wmY8XFVv8wh7XufjF/MQFvrrftuj6EFUbIiLL5zsHKKCkcArBGNFcqYkIifGJPDL/EdbvX0/nBp29DsmYykuLnDv2PP8LvHtBzzvFRT9v/6mPIxEQ3ch5xDSGegnO3+gGP7+wn7joV6sLkdXL9/uG0NkmBZvcJwC39rmV3y/4PVNTp/LMFaGtBzSm0snPgmO7i9+xn+ouPm+vc9evp5poQZyLd3RjiGkEdXq4F3n3ou//PLqRs69U7drx0yYFEXmZU1/8heK9kcxpNI1tyjVdrmHGihk8OeRJqkVW8zokY7xXmAvHdkHOLufvsV1wbGeJ17ugIPvUn69W17nAxzSGuE7QaODJi360e6E/8Ty6AUSc7b1v1XSmXyvlLN8zfhLjE/nwxw+Zu2Eu1513ndfhGBM6RQWQu/vnF/eSF/zjp5g8OSIaaraAGs2hXh9oPsJ5HdO0+B19dKNKVVUTjk6bFFTVFgYIguEdh9M8rjnJqcmWFEzFpEVOHfyp7uZzdp58nruHn1UuSCTUaOZc7OM6QuNBJy/+/o/q9UCsqTIcWLkqxKIiori9z+089c1T7MzaSYvap5wd3BjvFB6Ho1shexNkpzuPo1tOXvBzM6Ao/+efi2l88qJeP8H5W/KCH90o7HrXmDOzpFAOJsZP5E+L/8T05dP5/aDfex2OqWpUnSqb7HQ4sgmOpp98np0OOdspdocfGQO12kLNllD7UvcC3wJq+l3sY5paNU4lZUmhHLSv154h7YYwNW0qj17yKBFVvHeDCYGifGc6hOz04nf8J57nZxXfP6YpxLZ3qnNiOzjPY9tDXAfnPavKqbLKlBREJFVVbYa3s5AUn8RN79/Ews0LGdp+qNfhmIro+MGTF/sjJS78OduKd8mMiIbYds6FvtHFxS/8se0gqpZ338OEtbKWFOz24Sxd3/V66sXUY2raVEsK5tSKCpyqnJJ3+SeSQP6h4vtHN3Iu8g0HQuzNJ+/0Y9s7VTxWIjVnoaxJYW5IoqgCYqJimNBrAv9c9k/25+ynQc0GXodkvHD8kN9Fv8Tj6NbiE6BFVHPq9mPbQ4N+Je7220O1OM++hqm8ypoUvgtJFFVEYkIiL/3wEm+teot7LrzH63BMKPzsbr/Eo2Qf/egGUKs91O8LbcZBrXZ+d/streeOKXfirHUT4M5h0KbQt29fTUmpuGPn+k3px5HjR/g+6XtqR9f2OhxzNo4fLtGYe4a7fYk6ebfvX70T295JANVteRJTPkRkmar2LW0/a1MoZ7+/5PeMnj2aC6ZcwPtj36d74+5eh2RKKiqAnB2nv/CXdrfvX8Vjd/umgilrSaGfqv4QwnhKVdFLCgCLti5i3JxxZOVlMfXaqdzY40avQ6p6VJ0pGQ6vPfk4kQTsbt9UQqEqKSQBniaFymBQm0Gk3pHK2DljGf/eeJZsX8Kzw56lug0GCj5V567/8FrIWls8Cfj35qlW15lcze72TRVX1qRQapYxgWkW14wFtyzg4S8f5m/f/Y2UjBTe/cW7NI9r7nVoFZMWOXf4Jy74/gnAf7bN6EZQpxu0HQ+1uznP63SDmCY2YMsYyp4U9oYkiiqqWmQ1/nrlX7mwxYUkfpRIwr8SmDVmFoPbDvY6tPBVVOhU8ZS8689aB4XHTu5Xo5lz0W9/+8kLf+2uzpTKxpjTKmubQlNV3V2G/YcDLwKRQLKqPl3i/dbADJz1GSKBR1T1kzMdszK0KZzK2sy13DDrBjYe2Mgzlz/D/QPuR6rynWtRPhzZ+PM7/6yfoCjv5H41W7kXfL+7/jpdnVk3jTE+gbYphKxLqohEAuuBK4AdwFJgvKqu9dtnMpCmqq+KSDfgE1Vte6bjVtakAJCVl8XEf0/kvXXvMabbGKZdO4246Eo+QKkwD46sL3HXvxay1hdv7K3Vzu+ifyIJnAfVrFuvMYEIhy6p/YCNqpruBjQTGAWs9dtHgRP/q+sAu8oYT6VSO7o27/7iXZ5f8jyPfPkIq/as4v1x79OtUTevQzt3J+r8D62CQyvdv6uchKCFzj4S4YzardMNWozySwBdbK4eY8pJWZPClDLs2wLY7vd6B3BhiX3+D/hcRH4D1AIuP9WBROQO4A6A1q1blyGEikdEeGDgA1zQ/ALGzhlLvyn9mDZqGmO7j/U6tMDl7T950T/xOLy6eINvrbZQtye0ut5ZN7dOd6jd2Zm22RjjmTIlBVV9JcjnHw9MV9XnRWQA8IaI9FAtvgK3qk4GJoNTfRTkGMLS4LaDfd1Wx80Zx5LtS/jLFX8Jr3WeC3Ph8Dr3ou+XAI75Ffiq13cu/u1vc/7W6Ql1e9i8PcaEqVCup7ATaOX3uqW7zV8iMBxAVZeISAzQEOvlBECL2i1YeOtCHvz8QV74/gVSMlKYPWY2zeKalW8gWuSsxHVoFRxceTIBHNlwsuonItpp4G0yFOr1ci/+PZ1eQFW5wdyYCiaUSWEp0ElE2uEkgxuBm0rssw0YCkwXka5ADJAZwpgqnOqR1Xnxqhfp37I/Sf9JImFyArPHzOaSNpeE5oS5+4rf9fuqfo6e3Ce2vVv1M8b5W7enM/ArwtZsMqaiK7X3kVvf/6aqHizzwUVGAC/gdDedpqp/EpHHgRRV/cjtcTQFiMVpdH5IVT8/0zErc++j0qzeu5obZt1A+sF0nr3iWe7rf9/Zd1stPO5c7Itd/FfBsYyT+0Q3cO/4e528+NfpDtVig/OFjDHlJmhdUkXkSZy7/FRgGjBPy9KPNciqclIAOJx7mNv/fTsf/PgBY7uPJfma5MC7rWanw67PIOMz2LPg5N1/ZIzTxfPEhf/Ew5ZlNKbSCOo4BXFuR4cBt+NMdTEbmKqqm8410LKq6kkBQFV59ttneXT+o3Rp0IX3xr5H10Zdf75jQQ7s/fpkIjiy3tleqx00vwqaXOqUAmI72tw+xlRyQR2noKoqIruB3UABUA+YIyJfqOpD5xaqKSsR4aGLHqJv877cOOdG+iX347VRrzGm62hnxG+GmwT2fu30EIqMgcaXQee7odlVENfRSgDGmFMKpProXuAWYB+QDHyoqvkiEgFsUNUOoQ/zJCspFLfzwI+8+O9RtDu2nnH1a1O/KMt5o/Z50Gy4UyJodAlE1fA2UGOMp4JZUqgP3KCqW/03qmqRiFx9tgGas6TqNAq7pYEWmd/wl+h8cqOr8VlWFhtjOnLr8Ldp1PgCryM1xlRAEQHs8yngW2pKRGqLyIUAqrouVIEZP8cPwrZ34btE+LAlfNoblj/sjBzu8lsYupCYcdlk93+Dx7bvpPcbo/hm2zdeR22MqYACqT5KAxJO9Dhyq41SvFqruUpUH2kRHEh1SgO7PoX93znbqtWFZlc47QLNroSaP197YeWelYyePZoth7bw3BXPcc+F91Tt2VaNMUBwq4/EvwuqW21ko5SCLTcTMj53q4XmQZ47hq9+X+j2P07bQIN+pQ4Q69WkF0snLeW2D2/jvnn3sWTHEpKvTSa2uo0tMMaULpCLe7qI3AO86r6+C0gPXUhVRFEB7P/hZGngwDJAIbqhUwpodpVTKohpXOZD142py/vj3ueZb57hDwv/wKq9q3h/7Pt0adgl+N/DGFOpBFJ91Bh4CRiCM+p4PnCfqnoyP1GFrz46uALW/AkyvnDWCJYIaNDfKQk0Gw71E5xtQfJl+peMf288eQV5vDbqNUZ3Gx20YxtjKo6QLLITDip0UjiQCvOHOgPFWlzrJIKml4d8lbDth7cz5t0x/LDzBx4Y8ABPXf4UUTZPkTFVStDaFNyZSxOB7jgT1gGgqhPPKcKq5uByWHC5s1LY5V9DbNtyO3WrOq1YdNsifjvvtzy35DlSMlKYOXomTWKblFsMxpiKIZB6ijeApsCVwNc4U2AfCWVQlc7BlU5CiIqFy78q14RwQnRUNK+MfIUZ183gux3fkTA5gUVbF5V7HMaY8BZIUuioqn8EjqrqDGAkP19BzZzOodWwYChE1oChCyG2nafh3NL7Fr5L/I6YqBgGTx/M9bOuZ83eNZ7GZIwJH4EkhXz37yER6YGzlnLZu8RURYfWwPwhEFHdSQhx5TojyGn1btqbFXeu4PFLH2d++nx6vtqT2z68jS2HtngdmjHGY4EkhckiUg/4A/ARsBZ4JqRRVQaH18GCIc64gqELnUnowkhs9Vj+OPiPpN+bzv0D7mfm6pl0frkz9356L3uP2sJ3xlRVZ0wK7ujlLFU9qKqLVLW9qjZW1X+VU3wVU9ZPTgmBCCch1O7sdUSn1bBmQ54b9hwbfrOBW3vfyt+X/p32L7bnsYWPcTj3sNfhGWPK2RmTgqoWATY1dllkrYf5lwEKQxdA7YoxYKxVnVZMuXYKa+9ay4hOI3hi0RN0eKkDz3/7PMfyj3kdnjGmnARSffSliDwgIq1EpP6JR8gjq4iObHQSQlGBkxDqnGLhmzDXpWEXZv9iNimTUji/+fk88MUDdP57Z5JTkykoKvA6PGNMiAUyonnzKTarqrYPTUhnFraD145sgvmXOovaDF0IdXt4HVFQLNy8kEfnP8r3O7+nS4MuPHHZE4zuNpqIII66NsaEXqCD10r9n62q7U7x8CQhhK3sdKeEUHgMhsyvNAkB4LJ2l7EkcQkfjPuAyIhIxs4ZS78p/fh80+dUtNHwxpjSBVJSuOVU21X19ZBEVIqwKylkb4EvB0NBNgydD/X6eB1RyBQWFfLmyjf536/+l62Ht3JZ28t4auhTXNjShq0YE+6CVlIALvB7XAL8H3DtOUVXWRzd6pQQ8rNgyBeVOiEAREZEcmufW/np1z/x4vAXWb13Nf2n9rcBcMZUIoFUH/3G7zEJSAACmpxfRIaLyE8islFEHjnNPmNFZK2IrBGRt8sWvoeObocvL3NWRRv6pTO7aRURHRXNPRfew6Z7NvH4pY+zYPMCGwBnTCVxNq2FR4FS52oQkUjgH8BVQDdgvIh0K7FPJ+BR4CJV7Q7cdxbxlL+cHU4J4fh+p4RQ/3yvI/JEXHQcfxz8Rzbds8kGwBlTSZSaFETkPyLykfv4GPgJ+CCAY/cDNqpquqoeB2YCo0rsMwn4h6oeBPBqjYYyydnlDEzL3QuXfQ4NLvA6Is+VHAD3j6X/sAFwxlRQgZQUngOedx9PAYNU9ZRVQSW0ALb7vd7hbvPXGegsIv8Vke9EZPipDiQid4hIioikZGZmBnDqEDmW4ZQQjmXAZZ9BQ2tg9XdiANyau9bYADhjKqhAksI24HtV/VpV/wvsF5G2QTp/FNAJuBQYD0wRkbold1LVyaraV1X7NmrUKEinLqNju50SwrGdcOmn0GigN3FUADYAzpiKK5Ck8C5Q5Pe60N1Wmp1AK7/XLd1t/nYAH6lqvqpuBtbjJInwkrvXmf46Z7uTEBpf7HVEFcL5zc9n3s3zWHDLAlrEtWDSfybR45UevLvmXYq0qPQDGGPKXSBJIcptEwDAfV49gM8tBTqJSDsRqQ7ciDPLqr8PcUoJiEhDnOqk9ACOXX5yM50SQvYWGDwXGl/idUQVzokBcB+O+9AGwBkT5gJJCpki4huXICKjgH2lfUhVC4BfA/OAdcBsVV0jIo/7HW8eTnXUWmAh8KCq7i/rlwiZ3H1OCSE7HS79GJoM9jqiCktEGHXeKFbeuZIZ181gX84+rnzzSoa+PpRvtn3jdXjGGFcgI5o7AG8Bzd1NO4BbVHVjiGM7pXIb0Zy3H+YPhSM/weCPoenQ0J+zCskryGPyssk8ufhJ9h7dy4CWA3joooe4tsu1Nq+SMSEQ6IjmUpOC3wFjAVQ1+xxjOyflkhTyDjglhMPrYPBH0GxYaM9XheXk5/Ba2ms8v+R5Nh/aTJcGXXhg4ANM6DWB6Khor8MzptII2jQXIvJnEamrqtmqmi0i9UTkyeCEGYaOH4QFV8DhtTDoQ0sIIVazWk3u7nc363+znpmjZ1KzWk0m/WcSbV9sy9PfPM2h3ENeh2hMlRJIOf0qVfX9z3QHmo0IXUgeOn4IFgyDw6vhkg+g+SmHTZgQiIqIYlyPcSy7YxlfTviSXk168ej8R2n9t9Y8+PmD7Mja4XWIxlQJgSSFSBHxleNFpAZQ+cr1xw/Dwivh0Aq45D1oUTnzXrgTEYa2H8q8m+eRekcqV3e+mr999zfav9ie2/99u028Z0yIBZIU3gLmi0iiiCQj92k/AAAR4ElEQVQCXwCeTJsdMvlZsHA4HEiFi9+FFld7HZEB4pvF8/bot9nwmw3c2fdOZq2eRY9Xe3DNO9eweOti685qTAgE1NDsTj9xufvyC1WdF9KoziDoDc35R5yEsP8HuHg2tLo+eMc2QbUvZx+vLH2Fl394mX05++jfsj8PDXR6LEVGRHodnjFhLei9j/wOfDEwXlXvPtvgzkVQk0J+Nnx1FexbAhfNgtajg3NcE1I5+TlMXz6d55c8T/rBdDo36MwDAx5gQu8JxETFeB2eMWEpmIvsICLxIvIXEdkCPAH8eI7xea/gKHw90kkIA9+2hFCB1KxWk7suuIuffv0Ts8bMIq56HHd8fAdtX2jLU4uf4uCxg16HaEyFddqkICKdReR/ReRH4GWcGU9FVS9T1ZfLLcJQKMiBr6+BzG9gwJvQZqzXEZmzEBURxdjuY1k6aSnzb5lPn6Z9+J8F/0PrF1rzu3m/Y/vh7aUfxBhTzGmrj0SkCFgMJJ4YvSwi6aravhzj+5lzrj4qOOYkhL0LYcAb0Pam4AVnPLdi9wqe/fZZZq6eiYhwU8+beHDgg/Ro3MPr0IzxVDCqj24AMoCFIjJFRIYCEqwAPVFwDBaNgj0LoP8MSwiVUO+mvXnzhjfZdM8m7r7gbuasnUPPV3sy8u2RfL3la+uxZEwpApn7qBbOimnjgSE43VE/UNXPQx/ez511SaEwF74eBbu/gP6vQftbgx+cCTv7c/bzasqrvPT9S2TmZNKvRT8eGvgQ1513nfVYMlVK0BqaVfWoqr6tqtfgrImQBjwchBjL15a3YffncGGyJYQqpEHNBvxh0B/Yet9WXh35Kvtz9jPm3TF0/UdXJi+bTG5BrtchGhNWytwl1WtnXVJQhf1LoWG/4AdlKozCokI++PEDnvnvM6TsSqFxrcbc0+8efnXBr6hfo77X4RkTMiEbp+C1cps621RqqspXW77iL9/+hc82fkatarW4udfNJCUkcX6z8xGp2M1nxpRkScGYAK3cs5K/Lvkrs9fM5ljBMXo36U1SQhK/7PlL6tWo53V4xgSFJQVjyuhQ7iHeWfUOyWnJpGakEh0ZzZhuY0hKSGJwm8FWejAVmiUFY85BakYqU1On8taqtzicd5iO9TuSGJ/Irb1vpVlcM6/DM6bMLCkYEwQ5+Tm8t/Y9ktOSWbR1EZESydWdryYpIYnhHYcTFRHldYjGBMSSgjFBtn7/eqamTmXGihnsObqH5nHNub3P7UyMn0j7ep4O9DemVJYUjAmR/MJ85m6YS3JqMp9u/JQiLWJIuyEkxSdxfdfrbaZWE5YsKRhTDnZk7WD68ulMTZvKlkNbqBdTjwm9JpCUkETPJj29Ds8Yn6BOnX0OQQwXkZ9EZKOIPHKG/UaLiIpIqQEbE05a1m7JHwb9gU33bOKLCV8wrMMw/rnsn/T6Zy8uTL6QKcumcCTviNdhGhOwkJUURCQSWA9cAewAluIszrO2xH5xwFygOvBrVT1jMcBKCibc7cvZx5sr3yQ5NZk1mWuoVa0W47qPIykhif4t+1vXVuOJcCgp9AM2qmq6qh4HZuJMrFfSE8AzgE1CYyqFhjUbcl//+1j1q1UsSVzCjT1uZNaaWQycNpAer/bgb0v+xr6cfV6HacwphTIptMBZmOeEHe42HxFJAFqp6twzHUhE7hCRFBFJyczMDH6kxoSAiNC/ZX+Sr00m43cZTLlmCnHV47j/8/tp/nxzxs0ZxxebvqBIi7wO1RifkLYpnImIRAB/BX5X2r6qOllV+6pq30aNGoU+OGOCLC46jqSEJL5L+o6Vd67krgvu4sv0Lxn25jDav9ieJ75+wlaKM2EhlElhJ9DK73VLd9sJcUAP4Ct37ef+wEfW2Gwqu55NevLC8BfYef9OZo6eScf6HXnsq8do+2JbRrw1gg/WfUB+Yb7XYZoqKpQNzVE4Dc1DcZLBUuAmVV1zmv2/Ah6whmZTFaUfTOe1tNeYtnwau47sokmtJtzW5zaSEpLoWL+j1+GZSsDzhmZVLQB+DcwD1gGzVXWNiDwuIteG6rzGVETt67XniSFPsPW+rXx040f0a9GPZ799lk4vd2LIjCG8s+odWxDIlAsbvGZMmNqZtdM3MG7zoc3Ur1GfCb0mMClhEt0bd/c6PFPB2IhmYyqJIi1iweYFTEmd4rQ3FOUzoOUAJiVMYmz3sdSqXsvrEE0FYEnBmEoo82gmr694nSmpU/hp/0/EVY/jpp43MSlhEuc3P9/r8EwYs6RgTCWmqvx3+3+ZkjqF2Wtmk1uQS3zTeCYlTOKmnjdRJ6aO1yGaMGNJwZgq4lDuId5a+RZTUqewYs8KakTVYGz3sUxKmMTAVgNtWg0DWFIwpspRVZZlLGPKsim8vfptso9n061RN5Lik5jQewINazb0OkTjIUsKxlRh2cezmbV6FlNSp/D9zu+pHlmd68+7nkkJk7is3WVEiGeTGRiPWFIwxgCwas8qklOTeWPlGxzMPUiHeh1IjE/ktj632XrTVYglBWNMMbkFuby/7n2mpE7hqy1f+dabnpQwieEdhxMZEel1iCaELCkYY05rw/4NJKcmM33FdPYe3UvL2i2Z2GciE+Mn0qZuG6/DMyFgScEYU6rjhcf5eP3HTEmdwryN8wAY1mEYifGJDO84nLjoOI8jNMFiScEYUyZbD21lWto0pi2fxo6sHVSLqMagNoMY2WkkIzuPpFP9Tta9tQKzpGCMOSuFRYUs3raYTzZ8wtwNc1mb6ayg26FeB1+CGNRmEDFRMR5HasrCkoIxJii2HNriSxALNi8gtyCXmtVqcnn7yxnZaSQjOo2gZe2WXodpSmFJwRgTdDn5OXy15Svmrp/L3A1z2Xp4KwC9mvTyJYj+LfsTFRHlcaSmJEsKxpiQUlXW7VvH3PVz+WTjJ3yz7RsKigqoF1OP4R2HM6LTCIZ3HG4jqcOEJQVjTLk6nHuYzzd9zicbP+GTDZ+w9+heBOHClhc6bRGdRtKnaR9rrPaIJQVjjGeKtIhlu5b52iKW7loKQLPYZozoNIKRnUZyefvLrctrObKkYIwJG3uy9/DZxs+Yu2Eu8zbNIysvq1iX1xGdRtC5QWcrRYSQJQVjTFjKL8zn2+3fMnfD3FN2eR3RaQSD2w62Lq9BZknBGFMhnK7L69B2QxnecTiD2wyma6OuNrPrObKkYIypcI7lH2PhloU/6/LaoEYDLmlzCZe0voRBbQbRp2kf6/ZaRpYUjDEVmqqy+dBmFm1d5HtsOrgJgNjqsVzU6iIGtRnEoDaDuKD5BURHRXsccXgLi6QgIsOBF4FIIFlVny7x/v1AElAAZAITVXXrmY5pScGYqmvXkV0s3rrYSRLbFrF672oAoiOjubDlhQxq7SSJAa0GEFs91uNow4vnSUFEIoH1wBXADmApMF5V1/rtcxnwvarmiMivgEtVddyZjmtJwRhzwv6c/Xyz7RsWbV3E4m2LSc1IpVALiZRIEpol+EoSF7e+mPo16nsdrqfCISkMAP5PVa90Xz8KoKpPnWb/eODvqnrRmY5rScEYczpH8o6wZMcSX3XTDzt/IK8wD4AejXv4ShKXtLmE5nHNPY62fAWaFELZUtMC2O73egdw4Rn2TwQ+PdUbInIHcAdA69atgxWfMaaSiYuOY1iHYQzrMAxwVptbunOpr7rp9ZWv80rKK4DTBfZESWJQm0G0q9vOxkkQ2pLCGGC4qia5rycAF6rqr0+x783Ar4HBqpp3puNaScEYc7YKigpYvnu5rySxeNtiDhw7AEDzuOZOgnBLE5WtG2w4lBR2Aq38Xrd0txUjIpcDvyeAhGCMMeciKiKKvs370rd5X+4fcD9FWsTazLVO4/U2J1HMXD0TcLrBXtz6YqfhuuUAejXpRa3qtTz+BqEXypJCFE5D81CcZLAUuElV1/jtEw/MwSlRbAjkuFZSMMaEiqqSfjCdxdsW/6wbrCB0adiF+KbxzqOZ87dBzQYeRx0Yzxua3SBGAC/gdEmdpqp/EpHHgRRV/UhEvgR6AhnuR7ap6rVnOqYlBWNMedqZtZOUXSmk7U5zHhlpbM862VzaqnYrX4I4kSxa1W4Vdu0TYZEUQsGSgjHGa/ty9rF893LSMtJ8yeKnfT+hONfT+jXq/6xE0blBZyIjIj2L2ZKCMcaUo6PHj7Jyz0pfaSJtdxqr9q7ieOFxAGpWq0mvJr2KJYsejXuU28R/lhSMMcZj+YX5rNu3rliJYvnu5WTlZQFOw3fXhl2LVT/1adqHOjF1gh6LJQVjjAlDRVrE5oObi5Uo0nansTt7t2+f9vXa/6z6qVlcs3M6ryUFY4ypQHZn7y6WJNIy0nw9nwCa1GrCgwMf5HcDf3dWxw+HcQrGGGMC1DS2KVd1uoqrOl3l23Y49zAr9qzwJYvymJrDkoIxxoSpOjF1fNNwlJfKM4bbGGPMObOkYIwxxseSgjHGGB9LCsYYY3wsKRhjjPGxpGCMMcbHkoIxxhgfSwrGGGN8Ktw0FyKSCWz1Oo5z1BDY53UQYcR+j+Ls9zjJfovizuX3aKOqjUrbqcIlhcpARFICmYOkqrDfozj7PU6y36K48vg9rPrIGGOMjyUFY4wxPpYUvDHZ6wDCjP0exdnvcZL9FsWF/PewNgVjjDE+VlIwxhjjY0nBGGOMjyWFciQirURkoYisFZE1InKv1zF5TUQiRSRNRD72OhaviUhdEZkjIj+KyDoRGeB1TF4Skd+6/09Wi8g7IhLjdUzlSUSmicheEVntt62+iHwhIhvcv/WCfV5LCuWrAPidqnYD+gN3i0g3j2Py2r3AOq+DCBMvAp+p6nlAb6rw7yIiLYB7gL6q2gOIBG70NqpyNx0YXmLbI8B8Ve0EzHdfB5UlhXKkqhmqmuo+P4Lzn76Ft1F5R0RaAiOBZK9j8ZqI1AEGAVMBVPW4qh7yNirPRQE1RCQKqAns8jiecqWqi4ADJTaPAma4z2cA1wX7vJYUPCIibYF44HtvI/HUC8BDQJHXgYSBdkAm8JpbnZYsIrW8DsorqroTeA7YBmQAh1X1c2+jCgtNVDXDfb4baBLsE1hS8ICIxALvAfepapbX8XhBRK4G9qrqMq9jCRNRQALwqqrGA0cJQdVAReHWlY/CSZbNgVoicrO3UYUXdcYTBH1MgSWFciYi1XASwluq+r7X8XjoIuBaEdkCzASGiMib3obkqR3ADlU9UXKcg5MkqqrLgc2qmqmq+cD7wECPYwoHe0SkGYD7d2+wT2BJoRyJiODUGa9T1b96HY+XVPVRVW2pqm1xGhAXqGqVvRNU1d3AdhHp4m4aCqz1MCSvbQP6i0hN9//NUKpww7ufj4Bb3ee3Av8O9gksKZSvi4AJOHfFy93HCK+DMmHjN8BbIrIS6AP82eN4POOWmOYAqcAqnGtVlZryQkTeAZYAXURkh4gkAk8DV4jIBpzS1NNBP69Nc2GMMeYEKykYY4zxsaRgjDHGx5KCMcYYH0sKxhhjfCwpGGOM8bGkYIxLRAr9ugovF5GgjSgWkbb+s10aE66ivA7AmDByTFX7eB2EMV6ykoIxpRCRLSLyFxFZJSI/iEhHd3tbEVkgIitFZL6ItHa3NxGRD0Rkhfs4MT1DpIhMcdcI+FxEarj73+OusbFSRGZ69DWNASwpGOOvRonqo3F+7x1W1Z7A33FmdwV4GZihqr2At4CX3O0vAV+ram+c+YvWuNs7Af9Q1e7AIWC0u/0RIN49zp2h+nLGBMJGNBvjEpFsVY09xfYtwBBVTXcnNNytqg1EZB/QTFXz3e0ZqtpQRDKBlqqa53eMtsAX7uIoiMjDQDVVfVJEPgOygQ+BD1U1O8Rf1ZjTspKCMYHR0zwvizy/54WcbNMbCfwDp1Sx1F1UxhhPWFIwJjDj/P4ucZ9/y8klIn8JLHafzwd+Bb41qOuc7qAiEgG0UtWFwMNAHeBnpRVjyovdkRhzUg0RWe73+jNVPdEttZ47e2keMN7d9hucldIexFk17XZ3+73AZHdWy0KcBJHBqUUCb7qJQ4CXbBlO4yVrUzCmFG6bQl9V3ed1LMaEmlUfGWOM8bGSgjHGGB8rKRhjjPGxpGCMMcbHkoIxxhgfSwrGGGN8LCkYY4zx+f8zlficaNuylQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_train, color='g')\n",
    "plt.plot(epochs, accuracy_train, color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy ---- Loss')\n",
    "plt.title('Training phase')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.84375\n",
      "test accuracy: 0.8125\n",
      "test accuracy: 0.75\n",
      "test accuracy: 0.8125\n",
      "Test time execution 74.83174657821655\n",
      "Loss value for test phase: 0.8806149959564209\n",
      "Accuracy value for test phase: 0.7848442492012779\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0 \n",
    "start = time.time()\n",
    "for batch_id, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "    if MARVEL_USE: labels = labels-1\n",
    "\n",
    "    labels = torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "    if USE_CUDA: inputs, labels = inputs.to(device), labels.to(device)#cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _,label = torch.max(labels, 1)\n",
    "    loss = criterion(outputs, label.long())\n",
    "\n",
    "    test_loss += loss.data[0]\n",
    "    test_accuracy += (sum(np.argmax(outputs.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "\n",
    "    if batch_id % 100 == 0:\n",
    "        print(\"test accuracy:\", sum(np.argmax(outputs.data.cpu().numpy(), 1) == \n",
    "                               np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "end = time.time()\n",
    "print(\"Test time execution {}\".format(end-start))\n",
    "print(\"Loss value for test phase: {}\".format(test_loss /  len(dataloaders['val']))) \n",
    "print(\"Accuracy value for test phase: {}\".format(test_accuracy / len(dataloaders['val'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
