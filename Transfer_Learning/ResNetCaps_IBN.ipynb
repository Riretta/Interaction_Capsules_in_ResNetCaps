{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "#import import_ipynb\n",
    "import CapsNet_Layers \n",
    "\n",
    "verbose = False\n",
    "USE_CUDA = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import IBN_Net_master.models.imagenet as customized_models\n",
    "customized_models_names = sorted(name for name in customized_models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(customized_models.__dict__[name]))\n",
    "\n",
    "\n",
    "class IBN_ResNetCaps(nn.Module):\n",
    "        def __init__(self, NUM_CLASSES,ibn=True):\n",
    "            super(IBN_ResNetCaps, self).__init__()\n",
    "            self.NClass = NUM_CLASSES\n",
    "            model = customized_models.__dict__['resnet18_ibn_a'](pretrained=False,ibn=ibn)\n",
    "            modules = list(model.children())[:-4]\n",
    "            self.model=nn.Sequential(*modules)\n",
    "            self.decoder = CapsNet_Layers.Decoder()\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "            self.model.layer3 =  nn.Sequential(CapsNet_Layers.ConvLayer(in_channels = 128), CapsNet_Layers.PrimaryCaps(dimension = 32*6*6),CapsNet_Layers.DigitCaps(num_capsules = NUM_CLASSES,num_routes=32 * 6 * 6 ))\n",
    "            \n",
    "        def forward(self, x):\n",
    "            output = self.model(x)\n",
    "            \n",
    "            return output\n",
    "\n",
    "        def margin_loss(self, x, labels, size_average=True):\n",
    "            if verbose: print(\"x {}\".format(x.size()))\n",
    "            if verbose: print(\"labels {}\".format(labels.size()))\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True)) #<-L2\n",
    "            if verbose: print(\"v_c {}\".format(v_c.size()))\n",
    "            left = F.relu(0.9 - v_c).view(batch_size, -1) #**2\n",
    "            right = F.relu(v_c - 0.1).view(batch_size, -1) #**2\n",
    "\n",
    "            loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "\n",
    "            loss = loss.sum(dim=1).mean()\n",
    "\n",
    "            return loss\n",
    "\n",
    "        def model_loss(self, x, target):\n",
    "            return self.margin_loss(x, target)\n",
    "\n",
    "        def decoder(self, x, data):\n",
    "            classes = torch.sqrt((x ** 2).sum(2))\n",
    "            classes = F.softmax(classes)\n",
    "\n",
    "            _, max_length_indices = classes.max(dim=1)\n",
    "            masked = Variable(torch.eye(self.NClass))\n",
    "            if USE_CUDA: masked = masked.to(device)#cuda()\n",
    "            masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
    "\n",
    "            return masked  \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, ibn=False, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        if ibn:\n",
    "            self.bn1 = IBN(planes)\n",
    "        else:\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class IBN(nn.Module):\n",
    "    def __init__(self, planes):\n",
    "        super(IBN, self).__init__()\n",
    "        half1 = int(planes/2)\n",
    "        self.half = half1\n",
    "        half2 = planes - half1\n",
    "        self.IN = nn.InstanceNorm2d(half1, affine=True)\n",
    "        self.BN = nn.BatchNorm2d(half2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        split = torch.split(x, self.half, 1)\n",
    "        out1 = self.IN(split[0].contiguous())\n",
    "        out2 = self.BN(split[1].contiguous())\n",
    "        if verbose: print(\"out1 {}\".format(out1.size()))\n",
    "        if verbose: print(\"out2 {}\".format(out2.size()))\n",
    "        out = torch.cat((out1, out2), 1)\n",
    "        if verbose: print(\"out {}\".format(out.size()))\n",
    "        return out\n",
    "    \n",
    "        \n",
    "class IBN_ResNetCaps_trained(nn.Module):\n",
    "    def __init__(self, NUM_CLASSES):\n",
    "        super(IBN_ResNetCaps_trained, self).__init__()\n",
    "        self.NClass = NUM_CLASSES\n",
    "        scale = 64\n",
    "        self.inplanes = scale\n",
    "        resNetOriginal = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "        self.model = list(resNetOriginal.children())[:4]\n",
    "        self.model = torch.nn.Sequential(*self.model)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.layer1 = self._make_layer(BasicBlock, scale, 2)\n",
    "        self.model.layer2 = list(resNetOriginal.children())[5]  \n",
    "\n",
    "        for param in self.model.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.layer3 =  nn.Sequential(CapsNet_Layers.ConvLayer(in_channels = 128), CapsNet_Layers.PrimaryCaps(dimension = 32*6*6),CapsNet_Layers.DigitCaps(num_capsules = NUM_CLASSES,num_routes=32 * 6 * 6 ))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.InstanceNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()  \n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        ibn = True\n",
    "        if planes == 512:\n",
    "            ibn = False\n",
    "        layers.append(block(self.inplanes, planes, ibn, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, ibn))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def margin_loss(self, x, labels, size_average=True):\n",
    "            if verbose: print(\"x {}\".format(x.size()))\n",
    "            if verbose: print(\"labels {}\".format(labels.size()))\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True)) #<-L2\n",
    "            if verbose: print(\"v_c {}\".format(v_c.size()))\n",
    "            left = F.relu(0.9 - v_c).view(batch_size, -1) #**2\n",
    "            right = F.relu(v_c - 0.1).view(batch_size, -1) #**2\n",
    "\n",
    "            loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "\n",
    "            loss = loss.sum(dim=1).mean()\n",
    "\n",
    "            return loss\n",
    "\n",
    "    def model_loss(self, x, target):\n",
    "        return self.margin_loss(x, target)\n",
    "\n",
    "    def decoder(self, x, data):\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        classes = F.softmax(classes)\n",
    "\n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        masked = Variable(torch.eye(self.NClass))\n",
    "        if USE_CUDA: masked = masked.to(device)#cuda()\n",
    "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
    "\n",
    "        return masked  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = IBN_ResNetCaps_trained(10)\n",
    "#model = model.cuda(device)\n",
    "\n",
    "#optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.00001)\n",
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_transform = transforms.Compose([\n",
    "#    transforms.Resize((224,224)),\n",
    "#    transforms.ToTensor(),        \n",
    "#    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "#])\n",
    "\n",
    "\n",
    "#batch_size = 130\n",
    "#NUM_CLASSES = 10\n",
    "\n",
    "#print(\"CIFAR10\")\n",
    "#image_datasets = {'train': datasets.CIFAR10('../data', train=True, download=True, transform=dataset_transform),'val': datasets.CIFAR10('../data', train=False, download=True, transform=dataset_transform)}\n",
    "#print(\"Initializing Datasets and Dataloaders...\")\n",
    "#dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "#print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "#dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "#inputs, labels = next(iter(dataloaders['train']))\n",
    "#labels =torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "#inputs, labels = Variable(inputs), Variable(labels)\n",
    "#inputs = inputs.to(device)\n",
    "#labels = labels.to(device)\n",
    "\n",
    "#optimizer.zero_grad()\n",
    "\n",
    "#outputs = model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import import_ipynb\n",
    "#import ResNetCaps_E\n",
    "\n",
    "#model_2 = ResNetCaps_E.ResNetCaps(10)\n",
    "#model_2 = model_2.cuda(device)\n",
    "#optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_2.parameters()),lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
