{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import copy\n",
    "\n",
    "#matrix product for bilinear function\n",
    "euclidean = True\n",
    "kronecker = False\n",
    "outer_m = False\n",
    "\n",
    "verbose = False\n",
    "USE_CUDA = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import import_ipynb\n",
    "import ResNetCaps\n",
    "import ResNetCaps_IBN\n",
    "import DenseNetCaps\n",
    "import CapsNet_Layers\n",
    "\n",
    "\n",
    "def resume_model(name_file, model, optimizer): \n",
    "    if os.path.isfile(name_file):\n",
    "        print(\"=> loading checkpoint '{}'\".format(name_file))\n",
    "        checkpoint = torch.load(name_file)\n",
    "        #start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(name_file, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(name_file))\n",
    "\n",
    "    return start_epoch,model,optimizer\n",
    "\n",
    "class Bilinear(nn.Module):\n",
    "    def __init__(self,NUM_CLASSES, batch_size,not_ibn=True,model_path= \" \", model_name='ResNetCaps'):\n",
    "        super(Bilinear, self).__init__()\n",
    "        #Features function :\n",
    "        self.batch_size = batch_size\n",
    "        self.not_ibn = not_ibn ##########################da modificare\n",
    "        if not_ibn:\n",
    "            print(model_name)\n",
    "            if model_name == 'ResNetCaps':\n",
    "                print(\"sibling ResNetCaps\")\n",
    "                self.modelCaps1 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "                self.modelCaps2 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "            elif model_name == 'Dense':\n",
    "                print(\"sibling DenseNetCaps\")\n",
    "                self.modelCaps1 = DenseNetCaps.DenseNetCaps(NUM_CLASSES)\n",
    "                self.modelCaps2 = DenseNetCaps.DenseNetCaps(NUM_CLASSES)    \n",
    "            else:\n",
    "                print(\"sibling CapsNet\")\n",
    "                self.modelCaps1 = CapsNet_Layers.CapsNet(NUM_CLASSES)\n",
    "                self.modelCaps2 = CapsNet_Layers.CapsNet(NUM_CLASSES)               \n",
    "        else:\n",
    "            print(\"sibling ResNetCaps_IBN\")\n",
    "            model =  ResNetCaps_IBN.IBN_ResNetCaps(NUM_CLASSES)\n",
    "            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.001)\n",
    "            start_epoch,model,optimizer = resume_model(model_path, model, optimizer)\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.modelCaps1 = model\n",
    "            self.modelCaps2 = model\n",
    "        #Classification function:\n",
    "        self.modelLin = nn.Linear(NUM_CLASSES, NUM_CLASSES)\n",
    "        \n",
    "    def forward(self,inputs):    \n",
    "        #1) Extract features functions vectors (I need to do MATRIX OUTER PRODUCT)\n",
    "        if self.not_ibn:\n",
    "            digit1,_ ,_= self.modelCaps1(inputs)  #<--------------------------togli i _\n",
    "            digit2,_ ,_= self.modelCaps2(inputs)\n",
    "        else:\n",
    "            digit1 = self.modelCaps1(inputs)\n",
    "            digit2 = self.modelCaps2(inputs)            \n",
    "        #2) Classification Function    \n",
    "        output = self.modelLin(self.bilinear(digit1, digit2))#F.softmax()\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def model_loss(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        v_c = x\n",
    "        if verbose: print(\"v_c {}\".format(v_c.size()))\n",
    "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
    "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
    "\n",
    "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "\n",
    "        loss = loss.sum(dim=1).mean()\n",
    "        \n",
    "        return loss\n",
    " \n",
    "    def bilinear(self, A, B):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        Z_list = []\n",
    "        labels_size = A.size()[1]\n",
    "        batch = min(A.size()[0],self.batch_size)\n",
    "        for i in range(batch):\n",
    "        \n",
    "            a = A[i,:,:,0]\n",
    "            b = B[i,:,:,0]\n",
    "            #1.1) Pooling for aggregation of features vectors \n",
    "            if euclidean:\n",
    "                #EUCLIDEAN MATRIX PRODUCT\n",
    "                if verbose: print(\"Dim A {} B {}\".format(a.shape,b.shape))\n",
    "                x = torch.mm(a,torch.transpose(b,0,1))\n",
    "                x = torch.sum(x, dim=1)\n",
    "                #print(x.requires_grad)\n",
    "            if outer_m:\n",
    "                #OUTER MATRIX PRODUCT              \n",
    "                k = torch.sum(a,dim=1).detach()\n",
    "                j = torch.sum(b,dim=1).detach()\n",
    "                x = torch.ger(k,j)\n",
    "                x = torch.sum(x, dim=1)          \n",
    "            if kronecker:\n",
    "                #KRONECKER MATRIX PRODUCT\n",
    "                x = torch.kron(a.cpu().numpy(),b.cpu().numpy())\n",
    "                x = torch.from_numpy(x).float().to(device)\n",
    "                \n",
    "            x_binary = x.sign().detach().requires_grad_()\n",
    "            #print(x_binary)\n",
    "            y = x_binary *torch.sqrt(torch.FloatTensor.abs_(x))\n",
    "            z = y/torch.norm(y)       \n",
    "            \n",
    "            Z_list.append(y)\n",
    "            \n",
    "        Z = torch.cat(Z_list,0)\n",
    "        Z = Z.view(batch,labels_size,)\n",
    "        return Z      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
