{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ResNetCaps_IBN.ipynb\n",
      "importing Jupyter notebook from CapsNet_Layers.ipynb\n",
      "importing Jupyter notebook from Pets_Loader.ipynb\n",
      "importing Jupyter notebook from Animals_Loader.ipynb\n",
      "importing Jupyter notebook from Marvel_Loader.ipynb\n",
      "MARVEL\n",
      "Initializing Datasets and Dataloaders...\n",
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import import_ipynb\n",
    "import ResNetCaps_IBN\n",
    "import Pets_Loader\n",
    "import Animals_Loader\n",
    "import Marvel_Loader\n",
    "\n",
    "\n",
    "verbose = False\n",
    "USE_CUDA = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CIFAR10_USE = False\n",
    "MARVEL_USE =  True\n",
    "PETS_USE = False\n",
    "Animals_USE = False\n",
    "\n",
    "\n",
    "\n",
    "def lr_decrease(optimizer, lr_clip):  \n",
    "    for param_group in optimizer.param_groups:\n",
    "        init_lr = param_group['lr'] \n",
    "        param_group['lr'] = init_lr*lr_clip\n",
    "        \n",
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "def resume_model(name_file, model, optimizer): \n",
    "    if os.path.isfile(name_file):\n",
    "        print(\"=> loading checkpoint '{}'\".format(name_file))\n",
    "        checkpoint = torch.load(name_file)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(name_file, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(name_file))\n",
    "\n",
    "    return start_epoch,model,optimizer\n",
    "\n",
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 130\n",
    "\n",
    "\n",
    "if CIFAR10_USE: \n",
    "    NUM_CLASSES = 10\n",
    "    print(\"CIFAR10\")\n",
    "    name_dataset = \"CIFAR10\"\n",
    "    image_datasets = {'train': datasets.CIFAR10('../data', train=True, download=True, transform=dataset_transform),'val': datasets.CIFAR10('../data', train=False, download=True, transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "if MARVEL_USE: \n",
    "    \n",
    "    NUM_CLASSES = 26\n",
    "    print(\"MARVEL\")\n",
    "    name_dataset = \"MARVEL\"\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/marveldataset2016-master/FINAL.dat\"\n",
    "    #dat_file = \"/media/Data/rita/EYE-SEA/Verification/Datasets/marveldataset2016-master/FINAL.dat\"\n",
    "    image_datasets = {'train': Marvel_Loader.MARVEL_dataset(dat_file,train = True,transform=dataset_transform),'val': Marvel_Loader.MARVEL_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "if  PETS_USE:\n",
    "    NUM_CLASSES = 37\n",
    "    print(\"PETS\")\n",
    "    name_dataset = \"PETS\"    \n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Pets/Pet_Datasets\"\n",
    "    #dat_file = \"/media/Data/rita/EYE-SEA/Verification/Datasets/Pets/Pet_Datasets\"\n",
    "    image_datasets = {'train': Pets_Loader.PETS_dataset(dat_file,train = True,transform=dataset_transform),'val': Pets_Loader.PETS_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")    \n",
    "    \n",
    "if  Animals_USE:\n",
    "    NUM_CLASSES = 50\n",
    "    print(\"Animals\")\n",
    "    name_dataset = \"Animals\"     \n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Animals_with_Attributes2/JPEGImages\"\n",
    "    #dat_file = \"/media/Data/rita/EYE-SEA/Verification/Datasets/Animals_with_Attributes2/JPEGImages\"\n",
    "    image_datasets = {'train': Animals_Loader.Animals_dataset(dat_file,train = True,transform=dataset_transform),'val': Animals_Loader.Animals_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")    \n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "not_ibn = False\n",
    "model_path =  \"/home/rita/JupyterProjects/EYE-SEA/ResNet_CAPSNET/PY/ResNetCaps/\"+name_dataset+\"/checkpoint_99.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetCaps_IBN\n",
      "=> loading checkpoint '/home/rita/JupyterProjects/EYE-SEA/ResNet_CAPSNET/PY/ResNetCaps/MARVEL/checkpoint_99.pth.tar'\n",
      "=> loaded checkpoint '/home/rita/JupyterProjects/EYE-SEA/ResNet_CAPSNET/PY/ResNetCaps/MARVEL/checkpoint_99.pth.tar' (epoch 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CapsNet_Layers.ipynb:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"        u_hat = torch.matmul(W, x)\\n\",\n",
      "ResNetCaps_IBN.ipynb:78: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\\n\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.6076923076923076\n",
      "test accuracy: 0.6\n",
      "test accuracy: 0.7307692307692307\n",
      "Validation time execution 149.18897795677185\n",
      "Loss value for test phase: 0.4522314965724945\n",
      "Accuracy value for test phase: 0.6523304281924972\n"
     ]
    }
   ],
   "source": [
    "print(\"ResNetCaps_IBN\")\n",
    "model =  ResNetCaps_IBN.IBN_ResNetCaps(NUM_CLASSES)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.001)\n",
    "start_epoch,model,optimizer = resume_model(model_path, model, optimizer)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "start = time.time()\n",
    "\n",
    "for batch_id, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "    if MARVEL_USE: labels = labels-1    \n",
    "    labels =torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    masked = model.decoder(outputs, inputs)\n",
    "    \n",
    "    loss = model.model_loss(outputs, labels)\n",
    "    test_loss += loss.data\n",
    "    test_accuracy += (sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "    \n",
    "    if batch_id % 100 == 0:\n",
    "            print(\"test accuracy:\", sum(np.argmax(masked.data.cpu().numpy(), 1) == \n",
    "                                   np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size) )          \n",
    "end = time.time()   \n",
    "print(\"Validation time execution {}\".format(end-start))\n",
    "print(\"Loss value for test phase: {}\".format(test_loss / len(dataloaders['val'])))\n",
    "print(\"Accuracy value for test phase: {}\".format(test_accuracy / len(dataloaders['val'])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
