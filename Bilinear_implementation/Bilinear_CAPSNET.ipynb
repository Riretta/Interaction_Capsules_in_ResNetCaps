{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import import_ipynb\n",
    "import ResNetCaps\n",
    "\n",
    "verbose = False\n",
    "USE_CUDA = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MNIST_USE = False\n",
    "CIFAR10_USE = True\n",
    "MARVEL_USE = False\n",
    "\n",
    "#matrix product for bilinear function\n",
    "euclidean = False\n",
    "kronecker = False\n",
    "outer_m = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MARVEL_dataset(Dataset):\n",
    "    def __init__(self, dat_file,train = True, transform = None):   \n",
    "        self.root_dir = os.path.dirname(dat_file)\n",
    "        datContent = [i.strip().split(',') for i in open(dat_file).readlines()]\n",
    "        if train:\n",
    "            csv_file = os.path.join(self.root_dir, \"data_Train.csv\")\n",
    "        else:\n",
    "            csv_file = os.path.join(self.root_dir, \"data_Test.csv\")\n",
    "        with open(csv_file, \"w\") as f:\n",
    "            writer = csv.writer(f,delimiter=',')\n",
    "            writer.writerow([\"counter\", \"set\", \"class\", \"label\",\"location\"])\n",
    "            for line in datContent:\n",
    "                if train and line[1]=='1':\n",
    "                    if not(line[4] == '-'):\n",
    "                        writer.writerows([line])  \n",
    "                if not(train) and line[1] == '2':\n",
    "                    if not(line[4]=='-'):\n",
    "                        writer.writerows([line]) \n",
    "                \n",
    "        self.MARVEL_datafile = pd.read_csv(csv_file)       \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.MARVEL_datafile)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.MARVEL_datafile.iloc[idx,4]\n",
    "        image = self.__loadfile(img_name)\n",
    "        target = self.MARVEL_datafile.iloc[idx,2]\n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)\n",
    "            sample = self.transform(image)\n",
    "        else:\n",
    "            sample = image\n",
    "        return (sample,target)\n",
    "    \n",
    "    def __loadfile(self, data_file):\n",
    "        image = io.imread(data_file)\n",
    "        if len(image.shape)<3:\n",
    "            image = np.stack((image,)*3, axis=-1)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Initializing Datasets and Dataloaders...\n",
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "if CIFAR10_USE: \n",
    "    NUM_CLASSES = 10\n",
    "    print(\"CIFAR10\")\n",
    "    image_datasets = {'train': datasets.CIFAR10('../data', train=True, download=True, transform=dataset_transform),'val': datasets.CIFAR10('../data', train=False, download=True, transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "if MARVEL_USE: \n",
    "    NUM_CLASSES = 26\n",
    "    print(\"MARVEL\")\n",
    "    dat_file = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/marveldataset2016-master/FINAL.dat\"\n",
    "\n",
    "    image_datasets = {'train': MARVEL_dataset(dat_file,train = True,transform=dataset_transform),'val': MARVEL_dataset(dat_file,train = False,transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "if MNIST_USE: \n",
    "    dataset_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),        \n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    ])\n",
    "    NUM_CLASSES = 10\n",
    "    print(\"MNIST\")\n",
    "    image_datasets = {'train': datasets.MNIST('../data', train=True, download=True, transform=dataset_transform),'val': datasets.MNIST('../data', train=False, download=True, transform=dataset_transform)}\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bilinear(nn.Module):\n",
    "    def __init__(self,NUM_CLASSES):\n",
    "        super(Bilinear, self).__init__()\n",
    "        #Features function :\n",
    "        self.modelCaps1 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "        self.modelCaps2 = ResNetCaps.ResNetCaps(NUM_CLASSES)\n",
    "        #Classification function:\n",
    "        self.modelLin = nn.Linear(NUM_CLASSES, NUM_CLASSES)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        #1) Extract features functions vectors (I need to do MATRIX OUTER PRODUCT)\n",
    "        digit1, masked = self.modelCaps1(inputs)\n",
    "        digit2, masked = self.modelCaps2(inputs)\n",
    "        #2) Classification Function    \n",
    "        output = F.softmax(self.modelLin(self.bilinear(digit1, digit2)),dim=1)\n",
    "        \n",
    "        return output, masked\n",
    " \n",
    "    def bilinear(self, A, B):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        Z_list = []\n",
    "        labels_size = A.size()[1]\n",
    "        batch = min(A.size()[0],batch_size)\n",
    "        for i in range(batch):\n",
    "        \n",
    "            a = A[i,:,:,0]\n",
    "            b = B[i,:,:,0]\n",
    "            #1.1) Pooling for aggregation of features vectors \n",
    "            if euclidean:\n",
    "                #EUCLIDEAN MATRIX PRODUCT\n",
    "                if verbose: print(\"Dim A {} B {}\".format(a.shape,b.shape))\n",
    "                x = torch.mm(a,torch.transpose(b,0,1))\n",
    "                x = torch.sum(x, dim=1)\n",
    "            if outer_m:\n",
    "                #OUTER MATRIX PRODUCT\n",
    "                k = torch.sum(a,dim=1)\n",
    "                j = torch.sum(b,dim=1)\n",
    "                x = torch.ger(k,j)\n",
    "                x = torch.sum(x, dim=1)          \n",
    "            if kronecker:\n",
    "                #KRONECKER MATRIX PRODUCT\n",
    "                x = torch.kron(a.cpu().numpy(),b.cpu().numpy())\n",
    "                x = torch.from_numpy(x).float().to(device)\n",
    "                \n",
    "            y = torch.sign(x)*torch.sqrt(torch.FloatTensor.abs_(x))\n",
    "            z = y/torch.norm(y)       \n",
    "            \n",
    "            Z_list.append(z)\n",
    "            \n",
    "        Z = torch.cat(Z_list,0)\n",
    "        Z = Z.view(batch,labels_size)\n",
    "        return Z    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:30\n",
      "tensor([[ 0.0782,  0.0824,  0.1153,  0.1411,  0.0871,  0.1087,  0.1085,\n",
      "          0.0726,  0.0600,  0.1461],\n",
      "        [ 0.1781,  0.0892,  0.1025,  0.0810,  0.0566,  0.1077,  0.1410,\n",
      "          0.0769,  0.0988,  0.0681],\n",
      "        [ 0.1439,  0.0803,  0.0757,  0.0667,  0.0716,  0.1386,  0.1137,\n",
      "          0.0783,  0.1303,  0.1009],\n",
      "        [ 0.1634,  0.0877,  0.1046,  0.0794,  0.0613,  0.1338,  0.1293,\n",
      "          0.0752,  0.0918,  0.0735],\n",
      "        [ 0.1158,  0.0877,  0.0848,  0.1136,  0.0641,  0.1493,  0.1030,\n",
      "          0.0797,  0.1132,  0.0889],\n",
      "        [ 0.1520,  0.1015,  0.1173,  0.0866,  0.0476,  0.1099,  0.1418,\n",
      "          0.0820,  0.0944,  0.0669],\n",
      "        [ 0.0957,  0.1018,  0.1088,  0.1173,  0.0609,  0.1173,  0.1058,\n",
      "          0.0889,  0.0941,  0.1093],\n",
      "        [ 0.1723,  0.0813,  0.0779,  0.0729,  0.0747,  0.1244,  0.1328,\n",
      "          0.0668,  0.1055,  0.0914],\n",
      "        [ 0.0679,  0.0599,  0.0829,  0.1002,  0.1053,  0.1333,  0.0928,\n",
      "          0.0797,  0.0665,  0.2116],\n",
      "        [ 0.0971,  0.0717,  0.1111,  0.1031,  0.0832,  0.1307,  0.1128,\n",
      "          0.0861,  0.0678,  0.1365],\n",
      "        [ 0.0819,  0.0674,  0.1070,  0.1079,  0.0904,  0.1212,  0.1012,\n",
      "          0.0761,  0.0773,  0.1696],\n",
      "        [ 0.1947,  0.0664,  0.1094,  0.0737,  0.0593,  0.1410,  0.1101,\n",
      "          0.0689,  0.1074,  0.0691],\n",
      "        [ 0.1469,  0.0667,  0.1121,  0.0894,  0.0568,  0.1515,  0.0949,\n",
      "          0.0892,  0.0956,  0.0968],\n",
      "        [ 0.1328,  0.1010,  0.0938,  0.0912,  0.0576,  0.1352,  0.1323,\n",
      "          0.0718,  0.1167,  0.0676],\n",
      "        [ 0.1482,  0.0704,  0.0860,  0.0669,  0.0625,  0.1597,  0.1142,\n",
      "          0.0843,  0.1064,  0.1014],\n",
      "        [ 0.1851,  0.0710,  0.0911,  0.0630,  0.0641,  0.1250,  0.1144,\n",
      "          0.0760,  0.1279,  0.0823],\n",
      "        [ 0.1906,  0.0726,  0.1018,  0.0685,  0.0565,  0.1445,  0.1302,\n",
      "          0.0693,  0.0992,  0.0669],\n",
      "        [ 0.1863,  0.0688,  0.0914,  0.0623,  0.0712,  0.1284,  0.1168,\n",
      "          0.0740,  0.1144,  0.0865],\n",
      "        [ 0.1750,  0.0632,  0.1045,  0.0644,  0.0523,  0.1443,  0.1104,\n",
      "          0.0859,  0.1179,  0.0820],\n",
      "        [ 0.1595,  0.0812,  0.1062,  0.0932,  0.0505,  0.1209,  0.1158,\n",
      "          0.0847,  0.1162,  0.0718],\n",
      "        [ 0.1671,  0.0666,  0.0809,  0.0586,  0.0647,  0.1470,  0.1188,\n",
      "          0.0786,  0.1256,  0.0921],\n",
      "        [ 0.0732,  0.0847,  0.1128,  0.1417,  0.0833,  0.1046,  0.1056,\n",
      "          0.0796,  0.0582,  0.1564],\n",
      "        [ 0.1548,  0.0652,  0.0848,  0.0647,  0.0806,  0.1374,  0.1148,\n",
      "          0.0680,  0.1345,  0.0952],\n",
      "        [ 0.0709,  0.0796,  0.0970,  0.1554,  0.0924,  0.1119,  0.0997,\n",
      "          0.0735,  0.0575,  0.1621],\n",
      "        [ 0.1923,  0.0581,  0.0980,  0.0593,  0.0600,  0.1452,  0.1106,\n",
      "          0.0756,  0.1201,  0.0807],\n",
      "        [ 0.1348,  0.0791,  0.0936,  0.1119,  0.0602,  0.1359,  0.0937,\n",
      "          0.0736,  0.1341,  0.0832],\n",
      "        [ 0.1537,  0.0742,  0.1113,  0.0945,  0.0497,  0.1353,  0.1030,\n",
      "          0.0747,  0.1332,  0.0705],\n",
      "        [ 0.1582,  0.0805,  0.0938,  0.0907,  0.0583,  0.1221,  0.1160,\n",
      "          0.0826,  0.1194,  0.0785],\n",
      "        [ 0.1706,  0.0845,  0.0967,  0.0836,  0.0527,  0.1236,  0.1297,\n",
      "          0.0786,  0.1101,  0.0699],\n",
      "        [ 0.0916,  0.0784,  0.1248,  0.1249,  0.0861,  0.1084,  0.1030,\n",
      "          0.0723,  0.0694,  0.1410],\n",
      "        [ 0.1846,  0.0653,  0.1079,  0.0708,  0.0518,  0.1460,  0.1019,\n",
      "          0.0766,  0.1236,  0.0715],\n",
      "        [ 0.1674,  0.0790,  0.1202,  0.0990,  0.0493,  0.1251,  0.1258,\n",
      "          0.0737,  0.0941,  0.0664]], device='cuda:0')\n",
      "tensor(0.1812, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cublas_Sgemv only supports m, n, lda, incx, incyin the range 0 < [val] <= 2147483647 at /pytorch/aten/src/THC/THCBlas.cu:111",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bb00c4a8cafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cublas_Sgemv only supports m, n, lda, incx, incyin the range 0 < [val] <= 2147483647 at /pytorch/aten/src/THC/THCBlas.cu:111"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "model = Bilinear(NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "#optimizers\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.001)\n",
    "n_epochs = 30\n",
    "#train\n",
    "start = time.time()\n",
    "#batch_id = 100\n",
    "#inputs, labels = next(iter(dataloaders['train']))\n",
    "accuracy_train = []\n",
    "loss_train = []\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    model.train() \n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    print('epoch {}:{}'.format(epoch+1, n_epochs)) \n",
    "    for batch_id, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "        if MARVEL_USE: labels = labels-1\n",
    "        labels =torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, masked = model(inputs)\n",
    "        print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        train_accuracy += (sum(np.argmax(outputs.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            print(\"train accuracy:\", sum(np.argmax(outputs.data.cpu().numpy(), 1) == \n",
    "                                   np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "            if verbose: print(\"masked {}\".format(np.argmax(masked.data.cpu().numpy(), 1)))\n",
    "            if verbose: print(\"labels {}\".format(np.argmax(labels.data.cpu().numpy(), 1)))\n",
    "        #                batch_accuracy.append(sum(np.argmax(preds.data.cpu().numpy(), 1) == \n",
    "        #                                       np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "    accuracy_train.append(train_accuracy/len(dataloaders['train']))\n",
    "    loss_train.append(train_loss/len(dataloaders['train']))\n",
    "end = time.time()\n",
    "print(\"Training time execution {}\".format(end-start))\n",
    "print(\"Loss value for training phase: {}\".format(train_loss / len(dataloaders['train'])))\n",
    "print(\"Accuracy value for training phase: {}\".format(train_accuracy / len(dataloaders['train'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_train, color='g')\n",
    "plt.plot(epochs, accuracy_train, color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training phase')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0 \n",
    "start = time.time()\n",
    "for batch_id, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "\n",
    "    labels = torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "    if USE_CUDA: inputs, labels = inputs.to(device), labels.to(device)#cuda()\n",
    "\n",
    "    outputs, masked = model(inputs)\n",
    "    _,label = torch.max(labels, 1)\n",
    "    loss = criterion(outputs, label.long())\n",
    "\n",
    "    test_loss += loss.data[0]\n",
    "    test_accuracy += (sum(np.argmax(outputs.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "\n",
    "    if batch_id % 100 == 0:\n",
    "        print(\"test accuracy:\", sum(np.argmax(outputs.data.cpu().numpy(), 1) == \n",
    "                               np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "end = time.time()\n",
    "print(\"Test time execution {}\".format(end-start))\n",
    "print(\"Loss value for test phase: {}\".format(test_loss /  len(dataloaders['val']))) \n",
    "print(\"Accuracy value for test phase: {}\".format(test_accuracy /  len(dataloaders['val'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
